{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4247813-fc76-484e-b539-5eec33e94ab9",
   "metadata": {},
   "source": [
    "# Installation Instructions\n",
    "\n",
    "Download and install miniconda: https://conda.io/miniconda.html\n",
    "\n",
    "Create new environment with gsshapyorm and jupyter:\n",
    "\n",
    "```bash\n",
    "$ conda create -n gsshapyorm -c conda-forge gsshapyorm sqlalchemy<2 jupyter\n",
    "```\n",
    "\n",
    "Activate the new environment:\n",
    "\n",
    "```bash\n",
    "$ conda activate gsshapyorm\n",
    "```\n",
    "\n",
    "Navigate to the folder containing this notebook and start jupyter:\n",
    "\n",
    "```bash\n",
    "$ jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d72e347-2e49-478b-b339-6db395dbeb31",
   "metadata": {},
   "source": [
    "# Database Setup\n",
    "\n",
    "You will need a PostgreSQL database with the PostGIS 2.5 extension installed. This can easily created using docker:\n",
    "\n",
    "```bash\n",
    "$ docker run --name=gsshapy_postgis --env=POSTGRES_PASSWORD=mysecretpassword -p 5432:5432 -d postgis/postgis:12-2.5\n",
    "```\n",
    "\n",
    "After the container is created, create a database named `gsshapy_tutorial` and enable the PostGIS extension on it:\n",
    "\n",
    "```bash\n",
    "$ docker exec gsshapy_postgis su postgres -c \"createdb gsshapy_tutorial\"\n",
    "$ docker exec gsshapy_postgis su postgres -c \"psql -d gsshapy_tutorial -c \\\"CREATE EXTENSION postgis;\\\"\"\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9494da-30e7-43e4-ae59-cdf3ee799f8c",
   "metadata": {},
   "source": [
    "# Tutorial Data\n",
    "\n",
    "\n",
    "Download the tutorial data and unzip it: [tutorial-data.zip](https://gsshapy.readthedocs.io/en/latest/_downloads/tutorial-data.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8040c42c-dc24-4d81-be97-0bd2bc6c0130",
   "metadata": {},
   "source": [
    "# Create GsshaPy Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d066233-5976-40c8-8c6f-88294093053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsshapyorm.lib import db_tools as dbt\n",
    "\n",
    "# Adjust these per your database setup\n",
    "username = \"postgres\"\n",
    "password = \"mysecretpassword\"\n",
    "host = \"localhost\"\n",
    "port = \"5432\"\n",
    "database = \"gsshapy_tutorial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a89d69-709d-4172-8233-28a20df15f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gsshapy tables in the database\n",
    "sqlalchemy_url = dbt.init_postgresql_db(\n",
    "    host=host,\n",
    "    port=port,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    database=database,\n",
    ")\n",
    "sqlalchemy_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f84972-645e-4a85-b087-2848d27bd08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "\n",
    "engine = create_engine(sqlalchemy_url)\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# List tables\n",
    "table_names = sorted([table_name for table_name in inspector.get_table_names(schema='public')])\n",
    "table_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791bd816-b005-4cdf-b573-813c2a5bcc64",
   "metadata": {},
   "source": [
    "# Read a Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5e77fe-3ef9-43c9-b58c-fa42d288717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import Session\n",
    "from gsshapyorm.orm import ProjectFile\n",
    "\n",
    "# Update this to the location where you extracted tutorial-data.zip\n",
    "tutorial_data_dir = '/home/tethysdev/tutorial-data'\n",
    "filename = 'parkcity.prj'\n",
    "\n",
    "with Session(engine) as session:\n",
    "    project_file = ProjectFile()\n",
    "\n",
    "    # File objects have a read() method that can be used to read the file data into the database tables\n",
    "    project_file.read(\n",
    "        session=session,\n",
    "        directory=tutorial_data_dir,\n",
    "        filename=filename\n",
    "    )\n",
    "\n",
    "    # Each ProjectFile instance is associated with an entry in the proj_project_files table\n",
    "    print(f'Project File ID: {project_file.id}')\n",
    "\n",
    "    # Most files are read into multiple related tables and accessible through relationship properties\n",
    "    # For example, project files are read into the prj_project_files and prj_project_cards tables\n",
    "    # The \"projectCards\" property of ProjectFile objects is a relationship property that lists the related ProjectCard objects\n",
    "    for card in project_file.projectCards:\n",
    "        print(card)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aae5739-1e03-46db-8a63-35ff9e18f819",
   "metadata": {},
   "source": [
    "# Read an Entire GSSHA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56847e3-4fe8-44e7-aa2d-0e77dd07f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to close the session\n",
    "session = Session(engine)\n",
    "\n",
    "project_file = ProjectFile()\n",
    "\n",
    "# The ProjectFile object has methods for reading all the files of a GSSHA model, \n",
    "# as well as input and output subsets: readProject(), readInput(), and readOutput()\n",
    "project_file.readProject(\n",
    "    session=session,\n",
    "    directory=tutorial_data_dir,\n",
    "    projectFileName=filename\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adc1e86-5ef1-44a4-8d3a-7961cf516a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most files are related to the project file and can be accessed using a relationship property\n",
    "map_table = project_file.mapTableFile\n",
    "print(map_table)\n",
    "for index_map in map_table.indexMaps:\n",
    "    print(index_map)\n",
    "\n",
    "for table in map_table.mapTables:\n",
    "    print(table)\n",
    "    print(f'  {table.indexMap}')\n",
    "    for value in table.values:\n",
    "        print(f'  {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60bd645-cf78-494c-8d77-f99ebdac50f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_input_file = project_file.channelInputFile\n",
    "\n",
    "for link in channel_input_file.streamLinks:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7427a3ff-0152-497b-a986-d1d112bc1d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to close the session when you are done with it\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711bb01e-f41d-4fb1-8eae-21c3a1a34691",
   "metadata": {},
   "source": [
    "# Read with Spatial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18351adb-e032-4df4-8710-1cd9702babad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsshapyorm.orm import ProjectionFile\n",
    "\n",
    "# Don't forget to close the session\n",
    "session = Session(engine)\n",
    "\n",
    "srid = 26912  # UTM Zone 12N\n",
    "project_file = ProjectFile()\n",
    "\n",
    "# Add spatial=True to read rasters and vector data into PostGIS raster and geometry fields\n",
    "# Use the spatialReferenceID parameter to set the coordinate system with an EPSG code\n",
    "project_file.readProject(\n",
    "    session=session,\n",
    "    directory=tutorial_data_dir,\n",
    "    projectFileName=filename,\n",
    "    spatial=True,\n",
    "    spatialReferenceID=srid,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c70dcd-2dd6-4a62-bacf-a98eb5794f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_input_file = project_file.channelInputFile\n",
    "\n",
    "for link in channel_input_file.streamLinks:\n",
    "    # Notice that the geometry field is now populated with a binary string\n",
    "    print(f'{link.geometry[:50]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaba08f-9b5a-4d5d-b4ec-74ae76485b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometry objects provide convenience methods for serializing the data in other formats\n",
    "for link in channel_input_file.streamLinks:\n",
    "    print(link)\n",
    "    # GeoJSON\n",
    "    print(f'  GeoJSON: {link.getAsGeoJson(session)[:100]}...')\n",
    "    # WKT\n",
    "    print(f'  WKT: {link.getAsWkt(session)[:100]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0753fb-fb84-43fd-bcb1-2462f9009148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "import numbers\n",
    "\n",
    "\n",
    "# For coordinate conversion\n",
    "transformer = pyproj.Transformer.from_crs('epsg:26912', 'epsg:4326', always_xy=True)\n",
    "\n",
    "\n",
    "def reproject_coords(coords):\n",
    "    \"\"\"Reproject any GeoJSON coordinates.\"\"\"\n",
    "    if len(coords) < 1:\n",
    "        return []\n",
    "\n",
    "    if isinstance(coords[0], numbers.Number):\n",
    "        from_x, from_y, z = coords\n",
    "        to_x, to_y = transformer.transform(from_x, from_y)\n",
    "        return [to_x, to_y, z]\n",
    "\n",
    "    new_coords = []\n",
    "    for coord in coords:\n",
    "        new_coords.append(reproject_coords(coord))\n",
    "    return new_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3728d0-cd88-4cbf-b8a0-2e55fc57686d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import folium\n",
    "\n",
    "# GeoJSON FeatureCollection template\n",
    "geojson ={\n",
    "    \"type\":\"FeatureCollection\",\n",
    "    \"features\": [],\n",
    "}\n",
    "\n",
    "for link in channel_input_file.streamLinks:\n",
    "    link_geojson = json.loads(link.getAsGeoJson(session))\n",
    "    link_geojson['coordinates'] = reproject_coords(link_geojson['coordinates'])\n",
    "    \n",
    "    link_feature = {\n",
    "        # \"id\": link.id,\n",
    "        \"type\": \"Feature\",\n",
    "        \"properties\": {},\n",
    "        \"geometry\": link_geojson,\n",
    "    }\n",
    "        \n",
    "    geojson['features'].append(link_feature)\n",
    "\n",
    "map = folium.Map(location=(40.591026,-111.434263), zoom_start=12)\n",
    "folium.GeoJson(geojson, name=\"streams\").add_to(map)\n",
    "folium.LayerControl().add_to(map)\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f58909-e76b-4226-a863-8947f1442a65",
   "metadata": {},
   "source": [
    "# PostGIS Functions\n",
    "\n",
    "https://postgis.net/docs/manual-2.5/PostGIS_Special_Functions_Index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515a1ee9-b7d2-4261-91ac-68ad158a2b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsshapyorm.orm import IndexMap\n",
    "\n",
    "# Most files are related to the project file and can be accessed using a relationship property\n",
    "map_table = project_file.mapTableFile\n",
    "\n",
    "for index_map in map_table.indexMaps:\n",
    "    # Notice that the Raster field is now populated with a binary string: postgis well-known binary raster format\n",
    "    print(index_map)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d9a01-fbe9-4fe2-bb4e-e7b8bdf8901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import func\n",
    "\n",
    "# Enable the GDAL drivers for exporting the rasters\n",
    "session.execute(\"SET SESSION postgis.gdal_enabled_drivers = 'ENABLE_ALL';\")\n",
    "\n",
    "# PostGIS Functions Used\n",
    "# ST_AsGDALRaster: https://postgis.net/docs/manual-2.5/RT_ST_AsGDALRaster.html\n",
    "# ST_ColorMap: https://postgis.net/docs/manual-2.5/RT_ST_ColorMap.html\n",
    "# ST_Transform: https://postgis.net/docs/manual-2.5/ST_Transform.html\n",
    "# ST_AsGeoJSON: https://postgis.net/docs/manual-2.5/ST_AsGeoJSON.html\n",
    "# ST_Envelope: https://postgis.net/docs/manual-2.5/RT_ST_Envelope.html\n",
    "query = session.query(\n",
    "    IndexMap.filename,\n",
    "    # img\n",
    "    func.ST_AsGDALRaster(\n",
    "        func.ST_ColorMap(\n",
    "            func.ST_Transform(IndexMap.raster, 4326),\n",
    "            1, 'pseudocolor'\n",
    "        ),\n",
    "        'PNG', None, 4326\n",
    "    ).label('img'),\n",
    "    # extent\n",
    "    func.ST_AsGeoJSON(\n",
    "        func.ST_Envelope(func.ST_Transform(IndexMap.raster, 4326))\n",
    "    ).label('extent'),\n",
    ").filter(IndexMap.mapTableFile == map_table)  # Only Index Maps belonging to the current Map Table File\n",
    "\n",
    "# Make temporary directory to save GeoTIFF rasters\n",
    "geotiffs = []\n",
    "for row in query:\n",
    "    raster_path = row.filename.replace('idx', 'png')\n",
    "    with open(raster_path, 'wb') as f:\n",
    "        f.write(row.img)\n",
    "    geotiffs.append((raster_path, row.extent))\n",
    "print(geotiffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b391fa-cee9-4861-9f4b-285884d37569",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmap = folium.Map(location=(40.591026,-111.434263), zoom_start=12)\n",
    "for geotiff, extent in geotiffs:\n",
    "    extent = json.loads(extent)\n",
    "    lat = [c[1] for c in extent[\"coordinates\"][0]]\n",
    "    lng = [c[0] for c in extent[\"coordinates\"][0]]\n",
    "    bounds = [[min(lat), min(lng)], [max(lat), max(lng)]]\n",
    "    print(extent)\n",
    "    print(bounds)\n",
    "    img = folium.raster_layers.ImageOverlay(\n",
    "        name=geotiff,\n",
    "        image=geotiff,\n",
    "        bounds=bounds\n",
    "    )\n",
    "    img.add_to(rmap)\n",
    "\n",
    "folium.LayerControl().add_to(rmap)\n",
    "rmap\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb2402-4964-4718-b0ce-aac9983baa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to close the session when you are done with it\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9377d59a-7f71-4189-a005-dbaffa4205c7",
   "metadata": {},
   "source": [
    "# Export Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38949f09-72fe-41e7-a988-039cbafca6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The ProjectFile object has methods for writing all the files of a GSSHA model, \n",
    "# as well as input and output subsets: writeProject(), writeInput(), and writeOutput()\n",
    "# Don't forget to close the session\n",
    "\n",
    "# Here's a common workflow\n",
    "with Session(engine) as session:\n",
    "    # Enable the GDAL drivers for exporting the rasters\n",
    "    session.execute(\"SET SESSION postgis.gdal_enabled_drivers = 'ENABLE_ALL';\")\n",
    "\n",
    "    # Get a previouly loaded project\n",
    "    print(f'Project File ID: {project_file.id}')\n",
    "    project_file = session.query(ProjectFile).get(project_file.id)\n",
    "\n",
    "    # Modify something\n",
    "    total_time = project_file.getCard('TOT_TIME')\n",
    "    print(total_time)\n",
    "    total_time.value = 3600\n",
    "    session.commit()\n",
    "    \n",
    "    # Write only the input files in preparation for running\n",
    "    write_dir = os.path.join(os.getcwd(), 'example')\n",
    "    os.makedirs(write_dir, exist_ok=True)\n",
    "    project_file.writeInput(\n",
    "        session=session,\n",
    "        directory=write_dir,\n",
    "        name='example',\n",
    "    )\n",
    "\n",
    "    print('\\n'.join(os.listdir(write_dir)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e887ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import tempfile\n",
    "from tethys_dataset_services.engines import GeoServerSpatialDatasetEngine\n",
    "\n",
    "workspace = 'gssha'\n",
    "coverage_name = 'elevation'\n",
    "raster_map_file = '/home/tethysdev/gsshapyorm/notebooks/example/example.ele'\n",
    "default_style = 'gssha:elevation'\n",
    "\n",
    "# Get the WKT Projection of the srid\n",
    "projection_string = 'PROJCS[\"NAD83 / UTM zone 12N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-111],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26912\"]]'\n",
    "\n",
    "gs_engine = GeoServerSpatialDatasetEngine(\n",
    "    endpoint='http://localhost:8181/geoserver/rest',\n",
    "    username='admin',\n",
    "    password='geoserver',\n",
    "    public_endpoint='http://localhost:8181/geoserver/rest'\n",
    ")\n",
    "\n",
    "# create projection file in temp\n",
    "_, tmp_prj_path = tempfile.mkstemp(suffix='.prj')\n",
    "\n",
    "with open(tmp_prj_path, 'w') as tmp_prj_file:\n",
    "    tmp_prj_file.write(projection_string)\n",
    "\n",
    "# zip raster file and projection file together\n",
    "_, tmp_zip_path = tempfile.mkstemp(suffix='.zip')\n",
    "\n",
    "with zipfile.ZipFile(tmp_zip_path, 'w') as tmp_zip_file:\n",
    "    # NOTE: Give project file and raster file same basename when zipping\n",
    "    tmp_zip_file.write(tmp_prj_path, coverage_name + '.prj')\n",
    "    tmp_zip_file.write(raster_map_file, coverage_name)\n",
    "\n",
    "gs_engine.create_coverage_layer(\n",
    "    layer_id=f\"{workspace}:{coverage_name}\",\n",
    "    coverage_type=gs_engine.CT_GRASS_GRID,\n",
    "    coverage_file=tmp_zip_path,\n",
    "    default_style=default_style\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb9eaf-d9f2-4cbc-adf8-ca523ca1cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import tempfile\n",
    "from tethys_dataset_services.engines import GeoServerSpatialDatasetEngine\n",
    "\n",
    "workspace = 'gssha'\n",
    "coverage_name = 'combo'\n",
    "raster_map_file = '/home/tethysdev/gsshapyorm/notebooks/example/combo.idx'\n",
    "default_style = 'gssha:index_map'\n",
    "\n",
    "# Get the WKT Projection of the srid\n",
    "projection_string = 'PROJCS[\"NAD83 / UTM zone 12N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-111],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26912\"]]'\n",
    "\n",
    "gs_engine = GeoServerSpatialDatasetEngine(\n",
    "    endpoint='http://localhost:8181/geoserver/rest',\n",
    "    username='admin',\n",
    "    password='geoserver',\n",
    "    public_endpoint='http://localhost:8181/geoserver/rest'\n",
    ")\n",
    "\n",
    "# create projection file in temp\n",
    "_, tmp_prj_path = tempfile.mkstemp(suffix='.prj')\n",
    "\n",
    "with open(tmp_prj_path, 'w') as tmp_prj_file:\n",
    "    tmp_prj_file.write(projection_string)\n",
    "\n",
    "# zip raster file and projection file together\n",
    "_, tmp_zip_path = tempfile.mkstemp(suffix='.zip')\n",
    "\n",
    "with zipfile.ZipFile(tmp_zip_path, 'w') as tmp_zip_file:\n",
    "    # NOTE: Give project file and raster file same basename when zipping\n",
    "    tmp_zip_file.write(tmp_prj_path, coverage_name + '.prj')\n",
    "    tmp_zip_file.write(raster_map_file, coverage_name)\n",
    "\n",
    "gs_engine.create_coverage_layer(\n",
    "    layer_id=f\"{workspace}:{coverage_name}\",\n",
    "    coverage_type=gs_engine.CT_GRASS_GRID,\n",
    "    coverage_file=tmp_zip_path,\n",
    "    default_style=default_style\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42879e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "from requests.exceptions import RequestException\n",
    "from sqlalchemy.engine import URL\n",
    "from tethys_dataset_services.engines import GeoServerSpatialDatasetEngine\n",
    "\n",
    "workspace = 'gssha'\n",
    "store_name = 'gsshapy_tutorial'\n",
    "sql_template_file = '/home/tethysdev/gsshapyorm/sql/stream_nodes.sql'\n",
    "\n",
    "db_url = URL.create(\n",
    "    \"postgresql\",\n",
    "    username=\"postgres\",\n",
    "    password=\"mysecretpassword\",\n",
    "    host=\"172.17.0.2\",\n",
    "    port=\"5432\",\n",
    "    database=\"gsshapy_tutorial\",\n",
    ")\n",
    "\n",
    "gs_engine = GeoServerSpatialDatasetEngine(\n",
    "    endpoint='http://localhost:8181/geoserver/rest',\n",
    "    username='admin',\n",
    "    password='geoserver',\n",
    "    public_endpoint='http://localhost:8181/geoserver/rest'\n",
    ")\n",
    "\n",
    "# Create PostGIS Store\n",
    "try:\n",
    "    gs_engine.create_postgis_store(\n",
    "        store_id=f\"{workspace}:{store_name}\",\n",
    "        host=db_url.host,\n",
    "        port=db_url.port,\n",
    "        database=db_url.database,\n",
    "        username=db_url.username,\n",
    "        password=db_url.password\n",
    "    )\n",
    "except RequestException:\n",
    "    print(f'PostGIS Store named \"{workspace}:{store_name}\" already exists. Skipping.')\n",
    "\n",
    "# Get Layer Name\n",
    "layer_name = 'stream_nodes'\n",
    "\n",
    "# Get Default Style Name\n",
    "default_style = 'point'\n",
    "\n",
    "srid = 26912\n",
    "sql_context = {}\n",
    "\n",
    "with open(sql_template_file, 'r') as sql_template_file:\n",
    "    text = sql_template_file.read()\n",
    "    template = Template(text)\n",
    "    sql = ' '.join(template.render(sql_context).split())\n",
    "\n",
    "# Create SQL View\n",
    "gs_engine.create_sql_view_layer(\n",
    "    store_id=f\"{workspace}:{store_name}\",\n",
    "    layer_name=layer_name,\n",
    "    geometry_type=\"Geometry\",\n",
    "    srid=srid,\n",
    "    sql=sql,\n",
    "    default_style=default_style,\n",
    "    parameters=(\n",
    "        {\n",
    "            'name': 'pid',\n",
    "            'default_value': '5',\n",
    "            'regex_validator': '^[0-9]+$'\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b36e00-aaee-49e3-9d15-3c5bdde7cc77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
